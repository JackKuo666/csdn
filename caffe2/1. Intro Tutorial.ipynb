{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caffe2 Concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blobs and Workspace, Tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们通过搭建一个简单的网络，来简单了解caffe2的Blobs and Workspace, Tensors怎么用，以及之间的关系：\n",
    "我们这个网络有三层：\n",
    "\n",
    "1.一个全连接层 (FC)\n",
    "\n",
    "2.一个s型激活层，带有一个Softmax\n",
    "\n",
    "3.一个交叉熵loss层\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.定义数据，标签；并讲数据标签放入workspace中的“data”“label”中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from caffe2.python import workspace, model_helper\n",
    "import numpy as np\n",
    "\n",
    "# Create the input data\n",
    "data = np.random.rand(16, 100).astype(np.float32)\n",
    "\n",
    "# Create labels for the data as integers [0, 9].\n",
    "label = (np.random.rand(16) * 10).astype(np.int32)\n",
    "\n",
    "workspace.FeedBlob(\"data\", data)\n",
    "workspace.FeedBlob(\"label\", label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.使用model_helper新建一个model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model using a model helper\n",
    "m = model_helper.ModelHelper(name=\"my_first_net\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelHelper将会创建两个相关的net：\n",
    "\n",
    "1.初始化相关参数的网络(ref. init_net)\n",
    "\n",
    "2.执行实际训练的网络(ref. exec_net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.新建FC层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 新建operators之前，先定义w，b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])\n",
    "bias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 给m这个net新建一个FC的operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_1 = m.net.FC([\"data\", \"fc_w\", \"fc_b\"], \"fc1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.新建激活层和softmax层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = m.net.Sigmoid(fc_1, \"pred\")\n",
    "softmax, loss = m.net.SoftmaxWithLoss([pred, \"label\"], [\"softmax\", \"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：\n",
    "\n",
    "1.我们这里batch_size = 16，也就是一次16个samples同时训练；\n",
    "\n",
    "2.我们这里只是创建模型的定义，下一步开始训练；\n",
    "\n",
    "3.model会存储在一个protobuf structure中，我们可以通过以下命令查看model："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"my_first_net\"\n",
      "op {\n",
      "  input: \"data\"\n",
      "  input: \"fc_w\"\n",
      "  input: \"fc_b\"\n",
      "  output: \"fc1\"\n",
      "  name: \"\"\n",
      "  type: \"FC\"\n",
      "}\n",
      "op {\n",
      "  input: \"fc1\"\n",
      "  output: \"pred\"\n",
      "  name: \"\"\n",
      "  type: \"Sigmoid\"\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"label\"\n",
      "  output: \"softmax\"\n",
      "  output: \"loss\"\n",
      "  name: \"\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "}\n",
      "external_input: \"data\"\n",
      "external_input: \"fc_w\"\n",
      "external_input: \"fc_b\"\n",
      "external_input: \"label\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.net.Proto())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**查看初始化的参数:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"my_first_net_init\"\n",
      "op {\n",
      "  output: \"fc_w\"\n",
      "  name: \"\"\n",
      "  type: \"XavierFill\"\n",
      "  arg {\n",
      "    name: \"shape\"\n",
      "    ints: 10\n",
      "    ints: 100\n",
      "  }\n",
      "}\n",
      "op {\n",
      "  output: \"fc_b\"\n",
      "  name: \"\"\n",
      "  type: \"ConstantFill\"\n",
      "  arg {\n",
      "    name: \"shape\"\n",
      "    ints: 10\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.param_init_net.Proto())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.运行一次参数初始化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.RunNetOnce(m.param_init_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.创建训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.CreateNet(m.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3.训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 100 x 10 iterations\n",
    "for _ in range(100):\n",
    "    data = np.random.rand(16, 100).astype(np.float32)\n",
    "    label = (np.random.rand(16) * 10).astype(np.int32)\n",
    "\n",
    "    workspace.FeedBlob(\"data\", data)\n",
    "    workspace.FeedBlob(\"label\", label)\n",
    "\n",
    "    workspace.RunNet(m.name, 10)   # run for 10 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行后，您可以检查存储在输出blob（包含张量，即numpy数组）中的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0876148  0.07548364 0.09623323 0.12869014 0.08200206 0.10208801\n",
      "  0.12435256 0.11641801 0.09138598 0.09573159]\n",
      " [0.08656767 0.08965836 0.10828611 0.1141852  0.09495509 0.08777543\n",
      "  0.11474496 0.10817766 0.10231902 0.09333058]\n",
      " [0.08370095 0.07577838 0.10283273 0.12051839 0.09019332 0.1001257\n",
      "  0.12431574 0.10195971 0.10198188 0.09859312]\n",
      " [0.08037042 0.08022888 0.1113458  0.12137544 0.09024613 0.09120934\n",
      "  0.11656947 0.10384342 0.10305068 0.10176046]\n",
      " [0.0878759  0.07796903 0.10136125 0.12322115 0.0864681  0.09394205\n",
      "  0.11819859 0.11712413 0.08619776 0.10764208]\n",
      " [0.08172415 0.07318036 0.0948612  0.13026348 0.09646249 0.10189744\n",
      "  0.10387536 0.1055788  0.08963021 0.12252647]\n",
      " [0.07917343 0.08171824 0.11740194 0.11786009 0.09542355 0.10089807\n",
      "  0.10691947 0.08718182 0.09749852 0.11592486]\n",
      " [0.09023243 0.08145688 0.09926067 0.11211696 0.09406143 0.09656373\n",
      "  0.10264882 0.11141657 0.09514029 0.11710224]\n",
      " [0.08539043 0.08547576 0.10477988 0.11539709 0.08580235 0.09573507\n",
      "  0.11900022 0.11075822 0.09151191 0.106149  ]\n",
      " [0.08888969 0.07497442 0.1067399  0.12012165 0.0906563  0.09574833\n",
      "  0.11331636 0.09551872 0.09023768 0.12379707]\n",
      " [0.07795423 0.07904412 0.10365619 0.1125275  0.08462506 0.09732373\n",
      "  0.12132311 0.10707201 0.09885976 0.11761425]\n",
      " [0.08336885 0.07465281 0.10840832 0.11558709 0.08637662 0.11698949\n",
      "  0.10753863 0.10991579 0.08486839 0.11229403]\n",
      " [0.0904911  0.08106896 0.10705142 0.11207567 0.1001352  0.08801412\n",
      "  0.10004795 0.10290649 0.09353973 0.1246694 ]\n",
      " [0.08747555 0.07783487 0.11689501 0.11241519 0.08192006 0.09484729\n",
      "  0.11507696 0.10664993 0.10004598 0.10683927]\n",
      " [0.08289554 0.08357728 0.10166691 0.11176678 0.08568645 0.10207526\n",
      "  0.1217039  0.10599326 0.09480698 0.10982765]\n",
      " [0.07501717 0.0773883  0.09515747 0.12306631 0.1001178  0.09227181\n",
      "  0.12529895 0.09527896 0.10404698 0.11235628]]\n",
      "2.3265471\n"
     ]
    }
   ],
   "source": [
    "print(workspace.FetchBlob(\"softmax\"))\n",
    "print(workspace.FetchBlob(\"loss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.反向传播\n",
    "\n",
    "这个网络只包含前向传播，因此它不会学习任何东西。通过在正向传递中为每个运算符添加gradient operators来创建向后传递。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"my_first_net_4\"\n",
      "op {\n",
      "  input: \"data\"\n",
      "  input: \"fc_w\"\n",
      "  input: \"fc_b\"\n",
      "  output: \"fc1\"\n",
      "  name: \"\"\n",
      "  type: \"FC\"\n",
      "}\n",
      "op {\n",
      "  input: \"fc1\"\n",
      "  output: \"pred\"\n",
      "  name: \"\"\n",
      "  type: \"Sigmoid\"\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"label\"\n",
      "  output: \"softmax\"\n",
      "  output: \"loss\"\n",
      "  name: \"\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "}\n",
      "op {\n",
      "  input: \"loss\"\n",
      "  output: \"loss_autogen_grad\"\n",
      "  name: \"\"\n",
      "  type: \"ConstantFill\"\n",
      "  arg {\n",
      "    name: \"value\"\n",
      "    f: 1.0\n",
      "  }\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"label\"\n",
      "  input: \"softmax\"\n",
      "  input: \"loss_autogen_grad\"\n",
      "  output: \"pred_grad\"\n",
      "  name: \"\"\n",
      "  type: \"SoftmaxWithLossGradient\"\n",
      "  is_gradient_op: true\n",
      "}\n",
      "op {\n",
      "  input: \"pred\"\n",
      "  input: \"pred_grad\"\n",
      "  output: \"fc1_grad\"\n",
      "  name: \"\"\n",
      "  type: \"SigmoidGradient\"\n",
      "  is_gradient_op: true\n",
      "}\n",
      "op {\n",
      "  input: \"data\"\n",
      "  input: \"fc_w\"\n",
      "  input: \"fc1_grad\"\n",
      "  output: \"fc_w_grad\"\n",
      "  output: \"fc_b_grad\"\n",
      "  output: \"data_grad\"\n",
      "  name: \"\"\n",
      "  type: \"FCGradient\"\n",
      "  is_gradient_op: true\n",
      "}\n",
      "external_input: \"data\"\n",
      "external_input: \"fc_w\"\n",
      "external_input: \"fc_b\"\n",
      "external_input: \"label\"\n",
      "\n",
      "[[0.11452593 0.10101821 0.09836449 0.0965292  0.10351954 0.11437476\n",
      "  0.0841739  0.08410054 0.1032382  0.10015523]\n",
      " [0.10163245 0.09582136 0.10728257 0.09061375 0.09165412 0.10958022\n",
      "  0.09790237 0.08632593 0.10816205 0.11102515]\n",
      " [0.11153644 0.09187157 0.08876271 0.10034752 0.10996686 0.10122422\n",
      "  0.09731211 0.07600702 0.10907148 0.11390015]\n",
      " [0.10677353 0.09250082 0.09395255 0.09013956 0.11205406 0.10125393\n",
      "  0.0998921  0.08900981 0.10824097 0.10618276]\n",
      " [0.10816263 0.09636337 0.09732535 0.09815469 0.10086755 0.10827011\n",
      "  0.09060381 0.07663068 0.10915532 0.11446647]\n",
      " [0.10561427 0.09925039 0.09791987 0.09596141 0.10207485 0.10818447\n",
      "  0.09482063 0.08366729 0.09857398 0.11393285]\n",
      " [0.09989694 0.10426529 0.10590892 0.09590165 0.10164034 0.10572004\n",
      "  0.0843733  0.07041462 0.11091355 0.12096539]\n",
      " [0.11713242 0.09610002 0.09875591 0.09168133 0.1124823  0.09706804\n",
      "  0.09423647 0.07736441 0.09833553 0.11684357]\n",
      " [0.11634789 0.10220942 0.09840939 0.08635401 0.11169235 0.09972424\n",
      "  0.0881576  0.07687011 0.11021466 0.11002035]\n",
      " [0.0986582  0.10288956 0.09780209 0.09394148 0.10023048 0.11133306\n",
      "  0.09275422 0.07090774 0.11865855 0.11282461]\n",
      " [0.11411306 0.09094301 0.0921051  0.09122376 0.10246258 0.09556931\n",
      "  0.10687889 0.0793411  0.10633816 0.12102505]\n",
      " [0.11857571 0.10367715 0.0916706  0.09522462 0.10553856 0.1097901\n",
      "  0.08682371 0.08298165 0.10331775 0.10240018]\n",
      " [0.10449859 0.09788019 0.08315773 0.09780625 0.10613973 0.10121298\n",
      "  0.09945863 0.07901601 0.103154   0.12767594]\n",
      " [0.0995274  0.10280239 0.0894575  0.09834379 0.1094081  0.09976058\n",
      "  0.10002778 0.07689121 0.11048673 0.1132945 ]\n",
      " [0.10373392 0.09080214 0.09258449 0.09425651 0.12741047 0.10679753\n",
      "  0.09512977 0.073976   0.10132045 0.11398876]\n",
      " [0.09918068 0.10451347 0.08183451 0.11167922 0.11003976 0.09900602\n",
      "  0.08880362 0.08632898 0.11165588 0.10695779]]\n",
      "2.2832193\n"
     ]
    }
   ],
   "source": [
    "from caffe2.python import workspace, model_helper\n",
    "import numpy as np\n",
    "\n",
    "# Create the input data\n",
    "data = np.random.rand(16, 100).astype(np.float32)\n",
    "\n",
    "# Create labels for the data as integers [0, 9].\n",
    "label = (np.random.rand(16) * 10).astype(np.int32)\n",
    "\n",
    "workspace.FeedBlob(\"data\", data)\n",
    "workspace.FeedBlob(\"label\", label)\n",
    "\n",
    "# Create model using a model helper\n",
    "m = model_helper.ModelHelper(name=\"my_first_net\")\n",
    "\n",
    "\n",
    "weight = m.param_init_net.XavierFill([], 'fc_w', shape=[10, 100])\n",
    "bias = m.param_init_net.ConstantFill([], 'fc_b', shape=[10, ])\n",
    "\n",
    "\n",
    "fc_1 = m.net.FC([\"data\", \"fc_w\", \"fc_b\"], \"fc1\")\n",
    "pred = m.net.Sigmoid(fc_1, \"pred\")\n",
    "softmax, loss = m.net.SoftmaxWithLoss([pred, \"label\"], [\"softmax\", \"loss\"])\n",
    "\n",
    "# 反向传播 add ================\n",
    "m.AddGradientOperators([loss])\n",
    "# ============================\n",
    "\n",
    "workspace.RunNetOnce(m.param_init_net)\n",
    "workspace.CreateNet(m.net)\n",
    "\n",
    "# 可以查看加了反向传播之后，net中多出来三个operators的反向传播层\n",
    "print(m.net.Proto())\n",
    "#=========================================================\n",
    "\n",
    "# Run 100 x 10 iterations\n",
    "for _ in range(100):\n",
    "    data = np.random.rand(16, 100).astype(np.float32)\n",
    "    label = (np.random.rand(16) * 10).astype(np.int32)\n",
    "\n",
    "    workspace.FeedBlob(\"data\", data)\n",
    "    workspace.FeedBlob(\"label\", label)\n",
    "\n",
    "    workspace.RunNet(m.name, 10)   # run for 10 times\n",
    "\n",
    "print(workspace.FetchBlob(\"softmax\"))\n",
    "print(workspace.FetchBlob(\"loss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
