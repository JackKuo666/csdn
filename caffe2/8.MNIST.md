
# MNIST


在本教程中，我们将向您展示如何训练一个小型的卷积神经网络（CNN）。我们将在MNIST数据集上训练这个模型，它由标记的手写数字组成。数据集的每个样本都是一个28 x28像素的灰度（1通道）图像，一个手写的数字，标签是一个从0到9的整数。


对于我们的模型，我们将构建[LeNet模型](http://yann.lecun.com/exdb/lenet/)，将sigmoid激活替换为[ReLUs](http://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)。本教程还将提供使用简单的多层感知器（MLP）模型的选项，该模型不包括任何卷积运算符。您可以通过下面的*USE_LENET_MODEL*标志选择所需的型号。

在开始之前，请注意我们将在本教程中使用*ModelHelper*类。这个类可以帮助我们自然地处理参数初始化，并使我们不必分别维护param_init_net和net对象。

Before we start, let's import the necessities.


```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals
%matplotlib inline
from matplotlib import pyplot
import numpy as np
import os
import shutil
import operator
import caffe2.python.predictor.predictor_exporter as pe

from caffe2.python import (
    brew,
    core,
    model_helper,
    net_drawer,
    optimizer,
    visualize,
    workspace,
)

# If you would like to see some really detailed initializations,
# you can change --caffe2_log_level=0 to --caffe2_log_level=-1
core.GlobalInit(['caffe2', '--caffe2_log_level=0'])
print("Necessities imported!")

# If True, use the LeNet CNN model
# If False, a multilayer perceptron model is used
USE_LENET_MODEL = True
```

    Necessities imported!


## Data Download


我们将处理本教程所需的数据下载，并通过在用户主目录中设置名为“caffe2_notebooks”的顶级本地文件夹来跟踪训练期间的统计信息。对于数据下载，我们需要设置一个`tutorial_data`文件夹，对于训练统计，我们设置了一个`tutorial_files`文件夹。如果您已经运行本教程，那么您应该已经拥有这些文件夹。执行以下单元格时，将确保MNIST数据集的训练和测试lmdb数据库存在于`tutorial_data`文件夹中。


```python
# This section preps your image and test set in a lmdb database
def DownloadResource(url, path):
    '''Downloads resources from s3 by url and unzips them to the provided path'''
    import requests, zipfile, StringIO
    print("Downloading... {} to {}".format(url, path))
    r = requests.get(url, stream=True)
    z = zipfile.ZipFile(StringIO.StringIO(r.content))
    z.extractall(path)
    print("Completed download and extraction.")
    
# Setup the paths for the necessary directories 
current_folder = os.path.join(os.path.expanduser('~'), 'caffe2_notebooks')
data_folder = os.path.join(current_folder, 'tutorial_data', 'mnist')
root_folder = os.path.join(current_folder, 'tutorial_files', 'tutorial_mnist')
db_missing = False

# Check if the data folder already exists
if not os.path.exists(data_folder):
    os.makedirs(data_folder)   
    print("Your data folder was not found!! This was generated: {}".format(data_folder))

# Check if the training lmdb exists in the data folder
if os.path.exists(os.path.join(data_folder,"mnist-train-nchw-lmdb")):
    print("lmdb train db found!")
else:
    db_missing = True
    
# Check if the testing lmdb exists in the data folder   
if os.path.exists(os.path.join(data_folder,"mnist-test-nchw-lmdb")):
    print("lmdb test db found!")
else:
    db_missing = True

# Attempt the download of the db if either was missing
if db_missing:
    print("one or both of the MNIST lmbd dbs not found!!")
    db_url = "http://download.caffe2.ai/databases/mnist-lmdb.zip"
    try:
        DownloadResource(db_url, data_folder)
    except Exception as ex:
        print("Failed to download dataset. Please download it manually from {}".format(db_url))
        print("Unzip it and place the two database folders here: {}".format(data_folder))
        raise ex

# Clean up statistics from any old runs
if os.path.exists(root_folder):
    print("Looks like you ran this before, so we need to cleanup those old files...")
    shutil.rmtree(root_folder)
    
os.makedirs(root_folder)
workspace.ResetWorkspace(root_folder)

print("training data folder:" + data_folder)
print("workspace root folder:" + root_folder)
```

    lmdb train db found!
    lmdb test db found!
    training data folder:/home/jack/caffe2_notebooks/tutorial_data/mnist
    workspace root folder:/home/jack/caffe2_notebooks/tutorial_files/tutorial_mnist


> If the database wasn't found in the last step, [download the MNIST lmdb database](https://download.caffe2.ai/databases/mnist-lmdb.zip) or review the [datasets and databases notebook](https://github.com/caffe2/caffe2/blob/master/caffe2/python/tutorials/MNIST_Dataset_and_Databases.ipynb) on how to create the database from the MNIST dataset.

## Model Construction



我们将使用`ModelHelper`类来表示我们的主模型，并使用`brew`模块以及其他普通的Caffe2运算符来构建我们的模型。[`ModelHelper`](https://caffe2.ai/doxygen-python/html/classcaffe2_1_1python_1_1model__helper_1_1_model_helper.html)是一个特殊类，它存储有关参数初始化，网络结构，参数名称以及稍后映射到渐变的(mapping to gradients)大量信息。我们将在下面的其他地方看到它如何与`brew`一起使用。


为了避免混淆，请注意* model.MyOperator *是* model.net.MyOperator *的语法糖，它将相应的* MyOperator *运算符添加到* model.net *。

**Introduction to brew**


`brew`是辅助函数的集合，旨在简化向我们的模型添加复杂逻辑的过程（有关更多信息，请单击[此处](https://caffe2.ai/docs/brew.html)）。当我们想要添加参数初始化以及计算步骤时，例如，`brew`就派上用场了。现在，让我们更详细地探讨这个问题。


`brew`模块有一组包装函数，可以自动将参数初始化和实际计算分成两个网络。在引擎盖下，一个`ModelHelper`对象有两个底层网，`param_init_net`和`net`，它们分别记录初始化网络和主网络。 “model.params”也跟踪参数名称。

**High Level Process**

为了模块化，我们将模型的构造分为不同的部分：

    (1) The data input part (AddInput function)
    (1) 数据输入部分（AddInput函数）
    (2) The main computation part (AddModel function)
    (2) 主要计算部分（AddModel函数）
    (3) The training part - adding gradient operators, optimization algorithm, etc. (AddTrainingOperators function)
    (3) 训练部分 - 添加梯度算子，优化算法等（AddTrainingOperators函数）
    (4) The bookkeeping part, where we just print out statistics for inspection. (AddBookkeepingOperators function)
    (4) 簿记部分，我们只打印统计数据进行检查。 （AddBookkeepingOperators函数）
  
  
### Add Input


`AddInput`将从DB加载数据（特别是上面下载的lmdbs）。加载的MNIST数据以** NCHW **顺序存储为像素值，因此在批处理后，这将为我们提供形状为“[batch_size，num_channels，width，height]”的数据。更具体地说，由于我们的MNIST数据是尺寸为28x28px的8位（* uint8 *）灰度图像，我们作为网络输入的数据形状是`[batch_size，1,28,28]`，我们的标签类型是* int *形状为`[batch_size]`。
    

由于我们要进行浮点计算，我们将把数据转换为* float *数据类型。
为了获得更好的数值稳定性，我们将其缩小为[0,1]，而不是在[0,255]范围内表示数据。
请注意，我们正在为此运算符进行就地计算，因为我们不需要预先缩放的数据。
此外，在计算反向传递时，我们应该指定我们不需要数据准备部分的梯度计算。`StopGradient`完全是这样的：在前向传递中它什么都不做，在向后传递中它所做的就是告诉梯度生成器“gradient不需要通过这里”。


```python
def AddInput(model, batch_size, db, db_type):
    ### load the data from db - Method 1 using brew
    #data_uint8, label = brew.db_input(
    #    model,
    #    blobs_out=["data_uint8", "label"],
    #    batch_size=batch_size,
    #    db=db,
    #    db_type=db_type,
    #)
    ### load the data from db - Method 2 using TensorProtosDB
    data_uint8, label = model.TensorProtosDBInput(
        [], ["data_uint8", "label"], batch_size=batch_size,
        db=db, db_type=db_type)
    # cast the data to float
    data = model.Cast(data_uint8, "data", to=core.DataType.FLOAT)
    # scale data from [0,255] down to [0,1]
    data = model.Scale(data, data, scale=float(1./256))
    # don't need the gradient for the backward pass
    data = model.StopGradient(data, data)
    return data, label
```

### MLP Model Definition

**Note**: 这是标志* USE_LENET_MODEL = False *时使用的模型

现在我们要构建自己的模型。输入将是我们的数据blob($X$)，并且输出将是长度为10的向量，其包含网络对MNIST中的10个可能数字中的每一个的预测。

在这个多层感知器（MLP）架构中，将使用ReLU激活功能，并定义为：

$$Relu(x) =\begin{cases}x & if x > 0\\ 0 & otherwise\end{cases}$$


回想一下，MLP的每一层只是一些输入数据和权重矩阵（$W$）之间的矩阵乘法，然后是偏差（$b$）的加法。在机器学习中，这是通过一个完全连接的层实现的，该层在Caffe2中恰当地命名为[FC](https://caffe2.ai/docs/operators-catalogue.html#fc)。 然后将该乘法的结果传递给非线性激活函数（ReLU）。每个激活函数的输出作为输入数据传递到下一层，并通过各层重复此过程，如下所示：

$ {layer_1 = Relu(XW_1^T + b_1) } $

$ {layer_2 = Relu(layer_1W_2^T + b_2) } $

$ {...} $


一旦数据在前向传递中通过网络传播，我们将使用[Softmax](https://caffe2.ai/docs/operators-catalogue.html#softmax)运算符将每个数字的分数转换为概率。通常，分数总和为1（即$p_0 + ... + p_9 = 1.0 $）并且没有单个分数大于或等于1（即$ 0 <= p_i <= 1.0 $）。可以在[此处](http://deeplearning.net/tutorial/mlp.html)找到有关MLP的更详细说明。


在这个功能中，我们将首次使用`Brew`。在引擎盖（Under the hood）下，当我们调用`brew.fc（model，layer，...）`时，会发生以下情况：

- 通过调用`model.net.FC（[layer，W，b]，...）`将FC运算符添加到`model.net`
- $ W $和$ b $的初始化被添加到`model.param_init_net`中


希望这使得`brew`的便利性更加清晰!


```python
# Function to construct a MLP neural network
# The input 'model' is a model helper and 'data' is the input data blob's name
def AddMLPModel(model, data):
    size = 28 * 28 * 1
    sizes = [size, size * 2, size * 2, 10]
    layer = data
    for i in range(len(sizes) - 1):
        layer = brew.fc(model, layer, 'dense_{}'.format(i), dim_in=sizes[i], dim_out=sizes[i + 1])
        layer = brew.relu(model, layer, 'relu_{}'.format(i))
    softmax = brew.softmax(model, layer, 'softmax')
    return softmax
    
```

### LeNet Model Definition

**Note**: 这是标志* USE_LENET_MODEL = True *时使用的模型


下面是另一个可能（并且非常强大）的架构，称为LeNet。 与MLP模型的主要区别在于LeNet是卷积神经网络（CNN），因此使用卷积层（[Conv](https://caffe2.ai/docs/operators-catalogue.html#conv)），max pooling 层（[MaxPool](https://caffe2.ai/docs/operators-catalogue.html#maxpool)），[ReLUs](https://caffe2.ai/docs/operators-catalogue.html#relu)， *和* 全连接层（[FC](https://caffe2.ai/docs/operators-catalogue.html#fc)）图层。 有关CNN如何工作的完整解释超出了本教程的范围，但这里有一些好的资源供好奇的读者使用：

- [Stanford cs231 CNNs for Visual Recognition](http://cs231n.github.io/convolutional-networks/) (**Recommended**)
- [Explanation of Kernels in Image Processing](https://en.wikipedia.org/wiki/Kernel_%28image_processing%29) 
- [Convolutional Arithmetic Tutorial](http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html)


注意，此功能也使用`Brew`。但是，这次我们添加的不仅仅是`FC`和`Softmax`层。


```python
def AddLeNetModel(model, data):
    '''
    This part is the standard LeNet model: from data to the softmax prediction.
    
    For each convolutional layer we specify dim_in - number of input channels
    and dim_out - number or output channels. Also each Conv and MaxPool layer changes the
    image size. For example, kernel of size 5 reduces each side of an image by 4.

    While when we have kernel and stride sizes equal 2 in a MaxPool layer, it divides
    each side in half.
    '''
    # Image size: 28 x 28 -> 24 x 24
    conv1 = brew.conv(model, data, 'conv1', dim_in=1, dim_out=20, kernel=5)
    # Image size: 24 x 24 -> 12 x 12
    pool1 = brew.max_pool(model, conv1, 'pool1', kernel=2, stride=2)
    # Image size: 12 x 12 -> 8 x 8
    conv2 = brew.conv(model, pool1, 'conv2', dim_in=20, dim_out=50, kernel=5)
    # Image size: 8 x 8 -> 4 x 4
    pool2 = brew.max_pool(model, conv2, 'pool2', kernel=2, stride=2)
    # 50 * 4 * 4 stands for dim_out from previous layer multiplied by the image size
    # Here, the data is flattened from a tensor of dimension 50x4x4 to a vector of length 50*4*4
    fc3 = brew.fc(model, pool2, 'fc3', dim_in=50 * 4 * 4, dim_out=500)
    relu3 = brew.relu(model, fc3, 'relu3')
    # Last FC Layer
    pred = brew.fc(model, relu3, 'pred', dim_in=500, dim_out=10)
    # Softmax Layer
    softmax = brew.softmax(model, pred, 'softmax')
    
    return softmax
```


下面的`AddModel`函数允许我们轻松地从MLP切换到LeNet模型。只需在notebook的最顶部更改`USE_LENET_MODEL`，然后重新运行整个过程。


```python
def AddModel(model, data):
    if USE_LENET_MODEL:
        return AddLeNetModel(model, data)
    else:
        return AddMLPModel(model, data)
```

### Accuracy Layer

下面的`AddAccuracy`函数为模型添加了一个精度运算符（accuracy operator）。它使用softmax分数（softmax scores）和输入训练标签（记住这是一种监督学习技术）来报告当前训练批次的准确度分数（accuracy score）。通常**不**建议在训练期间对准确度分数(accuracy score)过度兴奋，因为该值没有给出关于泛化性能(generalization performance)的指示，但是训练准确性确实给出了模型是否正在学习的想法。通过训练过程跟踪准确性也将让我们建立一个很好的情节来总结训练运行。


```python
def AddAccuracy(model, softmax, label):
    """Adds an accuracy op to the model"""
    accuracy = brew.accuracy(model, [softmax, label], "accuracy")
    return accuracy
```

### Add Training Operators


下一个函数`AddTrainingOperators`将训练操作符添（Training Operators）加到模型中。请按照行内注释（inline comments）了解所有步骤。总而言之，这是我们指定模型如何计算* loss *以及特定*优化算法*及其超参数（hyperparameters）的地方。在本教程中，我们将使用vanilla SGD算法，该算法使用优化器模块中的`build_sgd`辅助函数（helper function）构建。作为此函数的结果，模型对象包含诸如参数名称（`model.param`）之类的信息以及从参数名称到相应梯度的映射。


```python
def AddTrainingOperators(model, softmax, label):
    """Adds training operators to the model."""
    # Compute cross entropy between softmax scores and labels
    xent = model.LabelCrossEntropy([softmax, label], 'xent')
    # Compute the expected loss
    loss = model.AveragedLoss(xent, "loss")
    # Track the accuracy of the model
    AddAccuracy(model, softmax, label)
    # Use the average loss we just computed to add gradient operators to the model
    model.AddGradientOperators([loss])
    # Specify the optimization algorithm
    optimizer.build_sgd(
        model,
        base_learning_rate=0.1,
        policy="step",
        stepsize=1,
        gamma=0.999,
    )
```

### Add Bookkeeping Operators


以下函数`AddBookkeepingOperations`添加了一些我们稍后可以检查的簿记操作符（book keeping operators）。这些运算符不会影响训练过程：它们仅收集统计信息并将其打印到文件或日志中。因此，这不是必要的步骤，但记账（bookkeeping）将使我们能够在训练结束后审查训练结果。


```python
def AddBookkeepingOperators(model):
    """This adds a few bookkeeping operators that we can inspect later.
    
    These operators do not affect the training procedure: they only collect
    statistics and prints them to file or to logs.
    """    
    # Print basically prints out the content of the blob. to_file=1 routes the
    # printed output to a file. The file is going to be stored under
    #     root_folder/[blob name]
    model.Print('accuracy', [], to_file=1)
    model.Print('loss', [], to_file=1)
    # Summarizes the parameters. Different from Print, Summarize gives some
    # statistics of the parameter, such as mean, std, min and max.
    for param in model.params:
        model.Summarize(param, [], to_file=1)
        model.Summarize(model.param_to_grad[param], [], to_file=1)
    # Now, if we really want to be verbose, we can summarize EVERY blob
    # that the model produces; it is probably not a good idea, because that
    # is going to take time - summarization do not come for free. For this
    # demo, we will only show how to summarize the parameters and their
    # gradients.
```

### Construct the Models


现在我们已经定义了函数，让我们实际创建用于训练（training），测试（testing）和模拟部署（simulated deployment）的模型（models）。如果您在下面看到警告消息，请不要惊慌。我们之前建立的功能现在将被执行。请记住我们正在做的四个步骤：

    (1) data input  
    
    (2) main computation
    
    (3) training 
    
    (4) bookkeeping


```python
#### Train Model
# Specify the data will be input in NCHW order
#  (i.e. [batch_size, num_channels, height, width])
arg_scope = {"order": "NCHW"}
# Create the model helper for the train model
train_model = model_helper.ModelHelper(name="mnist_train", arg_scope=arg_scope)
# Specify the input is from the train lmdb
data, label = AddInput(
    train_model, batch_size=64,
    db=os.path.join(data_folder, 'mnist-train-nchw-lmdb'),
    db_type='lmdb')
# Add the model definition (fc layers, conv layers, softmax, etc.)
softmax = AddModel(train_model, data)
# Add training operators, specify loss function and optimization algorithm
AddTrainingOperators(train_model, softmax, label)
# Add bookkeeping operators to save stats from training
AddBookkeepingOperators(train_model)

#### Testing model. 
# We will set the batch size to 100, so that the testing
#   pass is 100 iterations (10,000 images in total).
#   For the testing model, we need the data input part, the main AddModel
#   part, and an accuracy part. Note that init_params is set False because
#   we will be using the parameters obtained from the train model which will
#   already be in the workspace.
test_model = model_helper.ModelHelper(
    name="mnist_test", arg_scope=arg_scope, init_params=False)
data, label = AddInput(
    test_model, batch_size=100,
    db=os.path.join(data_folder, 'mnist-test-nchw-lmdb'),
    db_type='lmdb')
softmax = AddModel(test_model, data)
AddAccuracy(test_model, softmax, label)

#### Deployment model. 
# We simply need the main AddModel part.
deploy_model = model_helper.ModelHelper(
    name="mnist_deploy", arg_scope=arg_scope, init_params=False)
AddModel(deploy_model, "data")

```




    BlobReference("softmax")



### Visualize our Progress


现在，让我们看一下使用Caffe2具有的简单图形可视化工具，训练和部署模型的样子。如果以下命令失败，可能是因为您的计算机没有安装graphviz。您需要通过您选择的包管理器安装它。

如果图形看起来太小，请右键单击并在新选项卡中打开图像以便更好地检查。


```python
from IPython import display
graph = net_drawer.GetPydotGraph(train_model.net.Proto().op, "mnist", rankdir="LR")
display.Image(graph.create_png(), width=800)
```




![png](./markdown_img/8.output_22_0.png)





现在，上图显示了训练阶段发生的所有事情：白色节点是blob，绿色矩形节点是正在运行的运算符。您可能已经注意到像火车轨道这样的大规模平行线：这些是从前向传递中生成的blob到其后向运算符的依赖关系。


让我们通过仅显示必要的依赖关系并仅显示运算符来以更小的方式显示图形。如果仔细阅读，可以看到图的左半部分是向前传递，图的右半部分是向后传递，右边是一组参数更新和汇总运算符。


```python
graph = net_drawer.GetPydotGraphMinimal(
    train_model.net.Proto().op, "mnist", rankdir="LR", minimal_dependency=True)
display.Image(graph.create_png(), width=800)
```




![png](./markdown_img/8.output_24_0.png)





重要的是在这里重申`ModelHelper`类尚未执行任何操作的事实。到目前为止我们所做的就是声明网络（declare the network），它基本上创建了协议缓冲区（protocol buffers）指定的计算图。以下是我们如何为训练模型的主网络和参数初始化网络显示部分序列化协议缓冲区（serialized protocol buffer）的示例。


```python
print("*******train_model.net.Proto()*******\n")
print(str(train_model.net.Proto())[:400] + '\n...')
print("\n*******train_model.param_init_net.Proto()*******\n")
print(str(train_model.param_init_net.Proto())[:400] + '\n...')
```

    *******train_model.net.Proto()*******
    
    name: "mnist_train"
    op {
      input: "dbreader_/Users/nathaninkawhich/caffe2_notebooks/tutorial_data/mnist/mnist-train-nchw-lmdb"
      output: "data_uint8"
      output: "label"
      name: ""
      type: "TensorProtosDBInput"
      arg {
        name: "batch_size"
        i: 64
      }
    }
    op {
      input: "data_uint8"
      output: "data"
      name: ""
      type: "Cast"
      arg {
        name: "to"
        i: 1
      }
    }
    op {
      input: "data"
      output: "data
    ...
    
    *******train_model.param_init_net.Proto()*******
    
    name: "mnist_train_init"
    op {
      output: "dbreader_/Users/nathaninkawhich/caffe2_notebooks/tutorial_data/mnist/mnist-train-nchw-lmdb"
      name: ""
      type: "CreateDB"
      arg {
        name: "db_type"
        s: "lmdb"
      }
      arg {
        name: "db"
        s: "/Users/nathaninkawhich/caffe2_notebooks/tutorial_data/mnist/mnist-train-nchw-lmdb"
      }
    }
    op {
      output: "conv1_w"
      name: ""
      type: "XavierFill"
      arg {
        na
    ...


## Run Training


建立我们的模型并指定数据源后，我们现在可以运行训练程序。请注意，此过程可能需要一段时间才能运行。密切注意代码块仍在运行的星号（在[\*]中）或其他IPython指示符。


我们通过连续多次执行我们的网络来进行训练，每次都在一批新的输入上进行。请注意，在此过程中，我们可以获取工作空间中任何blob的值，包括准确性和loss。这使我们能够建立训练图并定期监测训练的准确性和损失。此外，一旦模型看到所有数据一次（1 epoch），训练就不会停止，而是一直持续到达到指定的迭代次数（iterations）。


使用MLP时，模型精度（model accuracy）很大程度上取决于参数的随机初始化和训练迭代次数（training iterations）。如果您的模型停留在大约50％的准确度，请重新运行（notebook），这将从另一个随机种子（random seed）和新参数初始化开始。


```python
# The parameter initialization network only needs to be run once.
# Now all the parameter blobs are initialized in the workspace.
workspace.RunNetOnce(train_model.param_init_net)

# Creating an actual network as a C++ object in memory.
#   We need this as the object is going to be used a lot
#   so we avoid creating an object every single time it is used.
# overwrite=True allows you to run this cell several times and avoid errors
workspace.CreateNet(train_model.net, overwrite=True)

# Set the iterations number and track the accuracy & loss
total_iters = 200
accuracy = np.zeros(total_iters)
loss = np.zeros(total_iters)

# MAIN TRAINING LOOP!
# Now, we will manually run the network for 200 iterations. 
for i in range(total_iters):
    workspace.RunNet(train_model.net)
    accuracy[i] = workspace.blobs['accuracy']
    loss[i] = workspace.blobs['loss']
    # Check the accuracy and loss every so often
    if i % 25 == 0:
        print("Iter: {}, Loss: {}, Accuracy: {}".format(i,loss[i],accuracy[i]))

# After the execution is done, let's plot the values.
pyplot.plot(loss, 'b')
pyplot.plot(accuracy, 'r')
pyplot.title("Summary of Training Run")
pyplot.xlabel("Iteration")
pyplot.legend(('Loss', 'Accuracy'), loc='upper right')
```

    Iter: 0, Loss: 2.41657829285, Accuracy: 0.03125
    Iter: 25, Loss: 0.419774413109, Accuracy: 0.875
    Iter: 50, Loss: 0.313294112682, Accuracy: 0.890625
    Iter: 75, Loss: 0.285170167685, Accuracy: 0.90625
    Iter: 100, Loss: 0.200987011194, Accuracy: 0.90625
    Iter: 125, Loss: 0.207681715488, Accuracy: 0.921875
    Iter: 150, Loss: 0.0973892956972, Accuracy: 0.984375
    Iter: 175, Loss: 0.209523797035, Accuracy: 0.9375





    <matplotlib.legend.Legend at 0x115c58c90>




![png](./markdown_img/8.output_28_2.png)


## Visualize Results


现在我们的模型已经过训练，我们可以看到我们的工作成果。但首先，查看上面训练期间打印的内容。在第一次迭代（iteration）中，批次0（batch 0）的训练精度（training accuracy）为3.1％，但是在第100次迭代中它很快收敛到九十五。plot也显示了这种趋势。


这是一个好兆头！


```python
### Let's look at some of the training data
pyplot.figure()
pyplot.title("Training Data Sample")
# Grab the most recent data blob (i.e. batch) from the workspace
data = workspace.FetchBlob('data')
# Use visualize module to show the examples from the last batch that was fed to the model
_ = visualize.NCHW.ShowMultiple(data)

### Let's visualize the softmax result
pyplot.figure()
pyplot.title('Softmax Prediction for the first image above')
pyplot.ylabel('Confidence')
pyplot.xlabel('Label')
# Grab and visualize the softmax blob for the batch we just visualized. Since batch size
#  is 64, the softmax blob contains 64 vectors, one for each image in the batch. To grab
#  the vector for the first image, we can simply index the fetched softmax blob at zero.
softmax = workspace.FetchBlob('softmax')
_ = pyplot.plot(softmax[0], 'ro')
```


![png](./markdown_img/8.output_30_0.png)



![png](./markdown_img/8.output_30_1.png)


### Visualize Learned Convolutional Filters（可视化学习卷积滤波器）

Note: 这仅适用于使用LeNet模型的情况（* USE_LENET_MODEL = True *）



对于卷积模型，我们也可以看到它们如何“思考”，即它们提出了哪些特征。我们不是取出对人类不太有意义的学习权重，而是获取在输入上对这些权重进行卷积的结果。在这里，我们获取第一个卷积层的输出特征映射* conv1 *，这是将第一层滤波器与最新训练数据批量进行卷积的结果。请注意，如果在评估阶段后重新运行此代码，则最后一个小批量将更改，因为评估（evaluation）和训练（training）共享相同的工作区。


```python
if USE_LENET_MODEL:
    pyplot.figure()
    pyplot.title("Conv1 Output Feature Maps for Most Recent Mini-batch")
    # Grab the output feature maps of conv1. Change this to conv2 in order to look into the second one.
    #  Remember, early convolutional layers tend to learn human-interpretable features but later conv
    #  layers work with highly-abstract representations. For this reason, it may be harder to understand
    #  features of the later conv layers.
    conv = workspace.FetchBlob('conv1')
    
    # We can look into any channel. Think of it as a feature model learned.
    # In this case we look into the 5th channel. Play with other channels to see other features
    conv = conv[:,[5],:,:]

    _ = visualize.NCHW.ShowMultiple(conv)

```


![png](./markdown_img/8.output_32_0.png)


## Test Model



还记得我们创建了一个测试网（test net）吗？现在我们已经训练了模型，并且我们的工作空间（workspace）包含训练的模型参数，我们可以对先前看不见的测试数据运行测试传递，以测试精度统计（test accuracy statistic）的形式检查我们的泛化性能。虽然* test_model *将使用从* train_model *获得的参数，但仍必须运行* test_model.param_init_net *来初始化输入数据。

我们只会运行100次迭代（iterations），因为我们有10,000个测试图像，而test_model的批量（batch size）大小为100.此外，我们将报告批量精确度的平均值（average of batch-wise accuracy），而不是报告每个单独图像的准确度分数。


```python
# param_init_net here will only create a data reader
# Other parameters won't be re-created because we selected init_params=False before
workspace.RunNetOnce(test_model.param_init_net)
workspace.CreateNet(test_model.net, overwrite=True)

# Testing Loop 
test_accuracy = np.zeros(100)
for i in range(100):
    # Run a forward pass of the net on the current batch
    workspace.RunNet(test_model.net)
    # Collect the batch accuracy from the workspace
    test_accuracy[i] = workspace.FetchBlob('accuracy')
    
# After the execution is done, let's plot the accuracy values.
pyplot.plot(test_accuracy, 'r')
pyplot.title('Accuracy over test batches.')
print('test_accuracy: %f' % test_accuracy.mean())
```

    test_accuracy: 0.950600



![png](./markdown_img/8.output_34_1.png)


## Deploy Model

### Save the Deploy Model



让我们使用经过训练的权重和偏差将部署模型（deploy model）保存到文件中。幸运的是，这一步骤的重要性是显而易见的，但这将使我们能够在另一个时间运行模型来运行更多测试，而不是每次都必须从头开始训练模型。当训练的参数仍在工作空间中时，必须在训练后立即执行此步骤。


```python
# construct the model to be exported
# the inputs/outputs of the model are manually specified.
pe_meta = pe.PredictorExportMeta(
    predict_net=deploy_model.net.Proto(),
    parameters=[str(b) for b in deploy_model.params], 
    inputs=["data"],
    outputs=["softmax"],
)

# save the model to a file. Use minidb as the file format
pe.save_to_db("minidb", os.path.join(root_folder, "mnist_model.minidb"), pe_meta)
print("Deploy model saved to: " + root_folder + "/mnist_model.minidb")
```

    Deploy model saved to: /Users/nathaninkawhich/caffe2_notebooks/tutorial_files/tutorial_mnist/mnist_model.minidb


### Load a Saved Model


注意：为了本教程，我们将在此处执行此操作，但此部分表示我们如何在另一个地方加载经过训练和保存的模型。


让我们从上一步加载已保存的部署模型，然后重新运行我们的测试以进行验证。


```python
# Grab and display the last data batch used before we scratch the workspace. This purely for our convenience...
blob = workspace.FetchBlob("data")
pyplot.figure()
pyplot.title("Batch of Testing Data")
_ = visualize.NCHW.ShowMultiple(blob)

# reset the workspace, to make sure the model is actually loaded
workspace.ResetWorkspace(root_folder)

# verify that all blobs from training are destroyed. 
print("The blobs in the workspace after reset: {}".format(workspace.Blobs()))

# load the predict net
predict_net = pe.prepare_prediction_net(os.path.join(root_folder, "mnist_model.minidb"), "minidb")

# verify that blobs are loaded back
print("The blobs in the workspace after loading the model: {}".format(workspace.Blobs()))

# feed the previously saved data to the loaded model
workspace.FeedBlob("data", blob)

# predict
workspace.RunNetOnce(predict_net)
softmax = workspace.FetchBlob("softmax")

print("Shape of softmax: ",softmax.shape)

# Quick way to get the top-1 prediction result
# Squeeze out the unnecessary axis. This returns a 1-D array of length 10
# Get the prediction and the confidence by finding the maximum value and index of maximum value in preds array
curr_pred, curr_conf = max(enumerate(softmax[0]), key=operator.itemgetter(1))
print("Prediction: ", curr_pred)
print("Confidence: ", curr_conf)

# the first letter should be predicted correctly
pyplot.figure()
pyplot.title('Prediction for the first image')
pyplot.ylabel('Confidence')
pyplot.xlabel('Label')
_ = pyplot.plot(softmax[0], 'ro')

```

    The blobs in the workspace after reset: []
    The blobs in the workspace after loading the model: [u'!!META_NET_DEF', u'!!PREDICTOR_DBREADER', u'conv1', u'conv1_b', u'conv1_w', u'conv2', u'conv2_b', u'conv2_w', u'data', u'fc3', u'fc3_b', u'fc3_w', u'pool1', u'pool2', u'pred', u'pred_b', u'pred_w', u'relu3', u'softmax']
    Shape of softmax:  (100, 10)
    Prediction:  8
    Confidence:  0.978955



![png](./markdown_img/8.output_38_1.png)



![png](./markdown_img/8.output_38_2.png)


这是MNIST教程的结束。我们希望本教程重点介绍Caffe2的一些功能以及创建简单MLP或CNN模型的难易程度。


```python

```
