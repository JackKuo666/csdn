{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.全连接层：正向传播，随机初始化w，b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上层输出是2个batch，每个batch有5个向量：\n",
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]]\n",
      "\n",
      "随机初始化w的参数的shape是：\n",
      "(5, 3)\n",
      "\n",
      "随机初始化w的参数是：\n",
      "[[ -2.02246258e-04  -2.86134686e-05   5.67536552e-05]\n",
      " [ -2.65147732e-05   3.46693399e-05  -4.84865213e-05]\n",
      " [ -8.56741462e-05  -1.36582254e-04  -1.63278178e-04]\n",
      " [  7.67300884e-05   4.15051110e-05   3.05435127e-05]\n",
      " [  2.03954211e-05   7.60062287e-05  -2.58280679e-04]]\n",
      "\n",
      "随机初始化b的参数的shape是：\n",
      "(3,)\n",
      "\n",
      "随机初始化b的参数是：\n",
      "[ 0.  0.  0.]\n",
      "\n",
      "全连接之后输出层的shape是：\n",
      "(2, 3)\n",
      "\n",
      "全连接之后输出是：\n",
      "[[-0.0001034   0.00017703 -0.00169928]\n",
      " [-0.00118995  0.00011195 -0.00361302]]\n"
     ]
    }
   ],
   "source": [
    "# 全连接层：正向传播\n",
    "import numpy as np\n",
    "x = np.arange(1,11,1).reshape(2,5)\n",
    "print (\"上层输出是2个batch，每个batch有5个向量：\\n\" + str(x))\n",
    "\n",
    "ww = std * np.random.randn(5,3)\n",
    "bb = std * np.zeros(3)\n",
    "print (\"\\n随机初始化w的参数的shape是：\\n\" + str(ww.shape))\n",
    "print (\"\\n随机初始化w的参数是：\\n\" + str(ww))\n",
    "print (\"\\n随机初始化b的参数的shape是：\\n\" + str(bb.shape))\n",
    "print (\"\\n随机初始化b的参数是：\\n\" + str(bb))\n",
    "a = x.dot(ww) + bb\n",
    "print (\"\\n全连接之后输出层的shape是：\\n\" + str(a.shape))\n",
    "print (\"\\n全连接之后输出是：\\n\" + str(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.全连接，反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "假设下层传过来的loss是：\n",
      "[[ 0.   0.2  0.4]\n",
      " [ 0.6  0.8  1. ]]\n",
      "\n",
      "1.对上层的输出求导值的shape：\n",
      "(2, 5)\n",
      "\n",
      "对上层的输出求导：\n",
      "[[-0.17798302 -0.21601246 -0.25409263 -0.29197948 -0.33008811]\n",
      " [-0.62808748 -0.75603666 -0.88432395 -1.01189021 -1.14018524]]\n",
      "\n",
      "2.对权重系数W求导之后更新的W值的shape：\n",
      "(5, 3)\n",
      "\n",
      "对权重系数W求导之后更新的W：\n",
      "[[-0.21620225 -0.30002861 -0.38394325]\n",
      " [-0.25202651 -0.35996533 -0.46804849]\n",
      " [-0.28808567 -0.42013658 -0.55216328]\n",
      " [-0.32392327 -0.47995849 -0.63596946]\n",
      " [-0.3599796  -0.53992399 -0.72025828]]\n",
      "\n",
      "3.对偏置系数b求导之后更新的b值的shape：\n",
      "(3,)\n",
      "\n",
      "对偏置系数b求导之后更新的b：\n",
      "[-0.036 -0.06  -0.084]\n"
     ]
    }
   ],
   "source": [
    "# 1.对上一层的输出（即当前层的输入）求导\n",
    "loss = np.arange(0,1.2,0.2).reshape(2,3)\n",
    "print (\"假设下层传过来的loss是：\\n\" + str(loss))\n",
    "residual_x = loss.dot(ww.T)\n",
    "print (\"\\n1.对上层的输出求导值的shape：\\n\" + str(residual_x.shape))\n",
    "print (\"\\n对上层的输出求导：\\n\" + str(residual_x))\n",
    "\n",
    "\n",
    "\n",
    "# 2.对权重系数W求导\n",
    "lr = 0.01\n",
    "reg = 0.75\n",
    "prev_grad_w = np.zeros_like(ww)\n",
    "ww -=  lr * (x.T.dot(loss) + prev_grad_w * reg)\n",
    "prev_grad_w = ww\n",
    "\n",
    "print (\"\\n2.对权重系数W求导之后更新的W值的shape：\\n\" + str(prev_grad_w.shape))\n",
    "print (\"\\n对权重系数W求导之后更新的W：\\n\" + str(prev_grad_w))\n",
    "\n",
    "# 3.对偏置系数b求导\n",
    "prev_grad_b = np.zeros_like(bb)\n",
    "bb -= lr * (np.sum(loss, axis=0))\n",
    "prev_grad_b = bb\n",
    "\n",
    "print (\"\\n3.对偏置系数b求导之后更新的b值的shape：\\n\" + str(prev_grad_b.shape))\n",
    "print (\"\\n对偏置系数b求导之后更新的b：\\n\" + str(prev_grad_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.numpy 的flatten层：将每个batch里的每个channel安顺序按行展开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2]\n",
      "   [ 3  4]]\n",
      "\n",
      "  [[ 5  6]\n",
      "   [ 7  8]]\n",
      "\n",
      "  [[ 9 10]\n",
      "   [11 12]]]\n",
      "\n",
      "\n",
      " [[[13 14]\n",
      "   [15 16]]\n",
      "\n",
      "  [[17 18]\n",
      "   [19 20]]\n",
      "\n",
      "  [[21 22]\n",
      "   [23 24]]]]\n",
      "[[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      " [13 14 15 16 17 18 19 20 21 22 23 24]]\n"
     ]
    }
   ],
   "source": [
    "# numpy 的flatten层：将每个batch里的每个channel安顺序按行展开\n",
    "import numpy as np\n",
    "q = np.arange(1,25,1).reshape(2,3,2,2)\n",
    "print (q)\n",
    "print (q.reshape(2,3*2*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
